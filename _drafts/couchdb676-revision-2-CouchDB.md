---
id: 678
title: CouchDB
date: 2010-01-14T23:41:23+00:00
author: Jilles
layout: revision
guid: http://www.jillesvangurp.com/2010/01/14/676-revision-2/
permalink: /2010/01/14/676-revision-2/
---
We did a little exercise at work to come up with a plan to scale to absolutely massive levels. One of the options I am in favor of is using something like <a href="http://couchdb.apache.org/">couchdb</a> to scale out. I was aware of couchdb before this but over the past few days I have learned quite a bit more that and am now even more convinced that couchdb is a perfect match for our needs. For obvious reasons I can't dive in what we want to do with it exactly. But of course itemizing what I like in couchdb should give you a strong indication that it involves shitloads (think hundreds of millions) of data items served up to shitloads of users (likewise). Not unheard of in this day and age (e.g. Facebook, Google). But also not something any off the shelf solution is going to handle.

Or so I thought.

<a href="http://wiki.apache.org/couchdb/">The couchdb wiki </a>has a two line description:

<blockquote>Apache CouchDB is a distributed, fault-tolerant and schema-free document-oriented database accessible via a RESTful HTTP/JSON API. Among other features, it provides robust, incremental replication with bi-directional conflict detection and resolution, and is queryable and indexable using a table-oriented view engine with JavaScript acting as the default view definition language.</blockquote>

This is not half the story but it gives a strong indication that quite a lot is being claimed here. Lets dig into the details a bit.

<strong>Fault tolerant.</strong> CouchDB stores json documents. So, a document is nothing more than a JSON data structure. Fair enough. No schemas to worry about, just data. A tree with nodes, attributes and values. Up to you to determine what goes in the tree. It has special attributes for the identity and revision of a document and some other couchdb stuff. Both id and revision are globally unique uuids. That means that any document stored in any instance of couchdb anywhere on this planet is uniquely identifiable and that any revision of such a document in any instance of couchdb is also uniquely identifiable. Couchdb uses a file as its datastore. Any write to a couchdb instance appends stuff to this file. Data in the file already is never overwritten. That's why it is fault tolerant. The only part of the file that can possibly get corrupted is at the end of the file, which is easily detected (on startup). Aside from that, couchdb is rock solid and guaranteed to never touch your data once it has been committed to disk. New revisions don't overwrite old ones, they are simply appended to the file (in full) to the end of the file with a new revision id.

<strong>Robust incremental replication.</strong> Two couchdb nodes can replicate to each other. Since documents are globally unique, it is easy to figure out which document is on which node. Additionally, the revision id allows couchdb to figure out what the correct revision is. Should you be so unlucky to have conflicting changes on both nodes, there are ways of dealing with conflict resolution as well. What this means is that any node can replicate to any other node. All it takes is bandwidth and time. It's bidirectional so you can have a master-master setup where both nodes consume writes and propagate changes to each other. The couchdb use the concept of "eventual consistency" to emphasize the fact that a network of couchdb nodes replicating to each other will eventually have the same data and be consistent with each other, regardless of the size of the network or how out of sync the nodes are at the beginning.

<strong>Cleanup by replicating</strong>. Because it is append only, a lot of cruft can accumulate in the bit of the file that is never touched again. Solution: add an empty node, tell the others to replicate to it. Once they are done you have a clean node and you can take out the old ones. Easy to automate. Data cleanup is not an issue.

<strong>Restful</strong>. CouchDBs native protocol is REST operations over HTTP. This means several things. First of all, there are no dedicated binary protocols, couchdb clients, drivers, etc. Instead you use normal REST and service related tooling to access couchdb. This is good because this is exactly what has made the internet work for all these years. Need caching? Pick your favorite caching proxy. Need load balancing? Same thing. Need access from language x on platform y? If it came with http support you are ready to roll.

<strong>Incremental map reduce</strong>. Map reduce is easy to explain if you understand functional programming. If you're not familiar with that, it's a divide and conquer type strategy to calculate stuff from lists of items. Very long lists.  How it works is as follows: the list is chopped into chunks. The chunks are processed concurrently to calculate something. This is called the map phase. Then the results are combined by collecting the results from processing each of the chunks. This is called the reduce phase. Basically, this is what Google uses to calculate e.g. pagerank and many thousands of other things on their local copy of the web (which they populate by crawling) the web regularly. CouchDB uses this as a generic querying mechanism. You define map and reduce functions in Javascript and couchdb takes care of applying them to the documents in its store. Moreover, it is incremental. So if you have n documents and those have been map reduced and you add another document, it basically incrementally calculates the map reduce stuff. I.e. it catches up real quick. Using this feature you can define views and query simply by accessing the views. The views are calculated on write, so accessing a view is cheap whereas writing involves the cost of storing and the background task of updating all the relevant views, which you control yourself by writing good map reduce functions. It's concurrent, so you can simply add nodes to scale. You can use views to index specific attributes, run clustering algorithms, implement join like query views, etc. Anything goes here. MS at one point had an experimental query optimizer backend for ms sql that was implemented using map reduce. Think expensive datamining SQL queries running as map reduce jobs on a generic map reduce infrastructure.

<strong>It's fast</strong>. It is implemented in erlang which is a language that is designed from the ground up to scale on massively parallel systems. It's a bit of a weird language but one with a long and very solid track record in high performance, high throughput type systems. Additionally, couchdb's append only and lock free files are wickedly fast. Basically, the primary bottleneck is the available IO to disk. Meaning that couchdb developers are claiming sustained write throughput that is above 80% of the IO bandwidth to disk. Add nodes to scale out.

So couchdb is an extremely scalable & fast storage system for documents that provides incremental map reduce for querying and mining the data; http based access and replication; and a robust append only, overwrite never, and lock free storage.

Is that all?

No.

Meebo decided that this was all nice and dandy but they needed to partition and shard their data instead of having all their data in every couchdb node. So they came up with <a href="http://tilgovi.github.com/couchdb-lounge/">CouchDB Lounge</a>. Basically what couchdb lounge does is enabled by the REST like nature of couchdb. It's a simple set of scripts that dynamically routes HTTP messages to the right couchdb node. Each node hosts not one but several (configurable) couchdb stores. As the nodes fill up, new nodes can be added and the existing stores are redistributed among them. Think of it as a distributed B tree. Each db calculates its map reduce views, the scripts in front of the loadbalancer take care of reducing these views to a coherent 'global' view. I.e. from the outside world, a couchdb lounge cluster looks just like any other couchdb node. Except it is effectively infinitely scalable both in the number of documents it can store as well in the read/write throughput. Couchdb looks just like any other couchdb instance in the sence that you can run the full test suite that comes with couchdb against and it will basically pass all tests. There's no difference from a functional perspective.

So, couchdb with couchdb lounge provides an off the shelf solution for storing, accessing and querying shitloads of documents. Precisely what we need. If shitloads of users come that need access, we can give them all the throughput they could possibly need by throwing more hardware in the mix. If shitloads is redefined to mean billions instead of millions, same solution. I'm sold. I want to get my hands dirty now. I'm totally sick and tired of having to deal with retarded ORM solutions that are neither easy, scalable, fast, robust, or even remotely convenient. I have some smart colleagues who are specialized in this stuff and way more who are not. The net result is a data layer that requires constant fire fighting to stay operational. The non experts routinely do stuff they shouldn't be doing that then requires lots of magic from our DB & ORM gurus. And to be fair, I'm not an expert. CouchDB is so close to being a silver bullet here that you'd have to be a fool to ignore the voices telling you that it is all too good to be true. But then again, I've been looking for flaws and so far have not come up with something substantial.

Sure, I have lots of unanswered questions and I'm hardly a couchdb expert (technically, any newby with more than an hour experience coding stuff for the thing outranks me here).